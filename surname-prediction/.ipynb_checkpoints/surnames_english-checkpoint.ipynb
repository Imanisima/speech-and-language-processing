{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Sequence Modeling - Russian vs English Surnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Goal\n",
    "---\n",
    "\n",
    "Develop and classifier for Russian vs English surnames.\n",
    "\n",
    "In this iteration we are going to:\n",
    "* Compute bigram frequencies for English names.\n",
    "* Compute bigram frequencies for Russian names.\n",
    "* Develop a bag of bigrams model for distinguishing English and Russian names.\n",
    "* Implement Good Turing Discounting Model Smoothing\n",
    "* Test performance of model using English data.\n",
    "\n",
    "------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import ngrams\n",
    "import collections\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "from nltk.corpus import brown # corpus of english words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB # Multi Naive Bayes with discrete values\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer # tokenize texts/build vocab\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer # tokenizes text and normalizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Let's perform some EDA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file into data frame.\n",
    "surname_csv = \"data_set/russian_and_english_dev.csv\"\n",
    "surname_df = pd.read_csv(surname_csv, index_col = None, encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename dev data columns.\n",
    "surname_df.rename(columns = {'Unnamed: 0':'surname', 'Unnamed: 1':'nationality'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "surname_df = surname_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>fairhurst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>941</td>\n",
       "      <td>wateridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>942</td>\n",
       "      <td>nemeth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>943</td>\n",
       "      <td>moroney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>944</td>\n",
       "      <td>goodall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       surname\n",
       "940  fairhurst\n",
       "941  wateridge\n",
       "942     nemeth\n",
       "943    moroney\n",
       "944    goodall"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve English names only\n",
    "english_df = surname_df.loc[surname_df[\"nationality\"] == \"English\"]\n",
    "english_df = english_df[[\"surname\"]]\n",
    "english_names = english_df.apply(lambda x: x.astype(str).str.lower())\n",
    "english_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all english names in txt file\n",
    "english_names.to_csv(\"data_set/corpus/english_names.txt\", sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mokrousov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>nurov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>judovich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>mikhailjants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>jandarbiev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        surname\n",
       "0     mokrousov\n",
       "1         nurov\n",
       "2      judovich\n",
       "3  mikhailjants\n",
       "4    jandarbiev"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Russian names only\n",
    "russian_df = surname_df.loc[surname_df[\"nationality\"] == \"Russian\"]\n",
    "russian_df = russian_df[[\"surname\"]]\n",
    "russian_names = russian_df.apply(lambda x: x.astype(str).str.lower())\n",
    "russian_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_names.to_csv(\"data_set/corpus/russian_names.txt\", sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Calculate Frequencies and Probabilities\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate bigrams and frequencies\n",
    "def generate_bigrams(names):\n",
    "    n_gram = collections.Counter()\n",
    "    n_gram_freq = 3\n",
    "    for c in names:\n",
    "        n_gram.update(Counter(c[idx : idx + n_gram_freq] for idx in range(len(c) - 1)))\n",
    "        \n",
    "    return n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting frequences in descending order\n",
    "def freq_sorted(n_gram):\n",
    "    [print(key, value) for (key, value) in sorted(n_gram.items(), key=lambda x: x[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve english bigrams\n",
    "eng_gram = generate_bigrams(english_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort freqencies\n",
    "# freq_sorted(eng_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_gram = generate_bigrams(russian_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = generate_bigrams(surname_df['surname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_sorted(rus_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = surname_df['surname'].apply(lambda x: re.sub('[^a-zA-Z]', '', x)) # features (x) needed to predict nationatlity\n",
    "target = surname_df['nationality'] # what we are predicting (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## Naiive Bayes\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(lowercase=True, analyzer='char', ngram_range=(1,3), strip_accents=\"ascii\", min_df=0.09, max_df=1.0)\n",
    "X = cv.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1305,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1305, 28)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Data\n",
    "\n",
    "To make the data a little more accurate in it's predictions, we are going to split the surnames into train (80%) and test (20%) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to train the model\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "surname_model = GaussianNB()\n",
    "surname_model.fit(x_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surname_model.predict(x_test.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     English       0.62      0.98      0.76        86\n",
      "     Russian       0.98      0.70      0.82       175\n",
      "\n",
      "    accuracy                           0.79       261\n",
      "   macro avg       0.80      0.84      0.79       261\n",
      "weighted avg       0.86      0.79      0.80       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 84   2]\n",
      " [ 52 123]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.7931034482758621 \n"
     ]
    }
   ],
   "source": [
    "print(f\"f1_score: {f1_score(y_test, y_pred, average='micro')} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__observe__: Accuracy is almost at 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_turing_smoothing(n_gram):\n",
    "    dict(n_gram)\n",
    "    smoothing = {}\n",
    "    \n",
    "    result = None\n",
    "    \n",
    "    \n",
    "    for k in n_gram:\n",
    "        result = (n_gram[k] + 1 / n_gram[k])\n",
    "        smoothing[k] = result\n",
    "        \n",
    "    return smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ The smoothing method we will use is the Good-Turing Discounting Formula. It is perfect for accounting for bigrams that have yet to occur.\n",
    "\n",
    "Equation: C^* = (c + 1) Nc+1/Nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english metaparameters\n",
    "eng_meta = good_turing_smoothing(eng_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# russian metaparameters\n",
    "rus_meta = good_turing_smoothing(rus_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using English Data to Test Performance\n",
    "The data we will be using is from the United States Naval Academy. It is 7 KB and has a good amount of English first names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of First Names\n",
    "names = open(\"data_set/corpus/name_catalog.txt\", \"r\")\n",
    "test_names = [x.rstrip() for x in names.readlines()]\n",
    "test_names = [x.lower() for x in test_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in test_names:\n",
    "    name = [name]\n",
    "    reshape_feature = cv.transform(name)\n",
    "    y_pred = surname_model.predict(reshape_feature.toarray().reshape(-1,1))\n",
    "    \n",
    "    f = open(\"results/test_pred.txt\",\"a\")\n",
    "    f.write(f\"{name}: {y_pred} \\n\\n\") \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "All of the output can be found in results/test_pred.txt. However, her is a snapshot:\n",
    "\n",
    "__michael__: \n",
    "\n",
    "['Russian' 'English' 'English' 'Russian' 'Russian' 'English' 'Russian'\n",
    " 'English' 'English' 'English' 'Russian' 'Russian' 'English' 'English'\n",
    " 'English' 'Russian' 'Russian' 'English' 'English' 'English' 'English'\n",
    " 'English' 'English' 'English' 'English' 'English' 'English' 'English']\n",
    " \n",
    "__christopher__: \n",
    "\n",
    "['English' 'English' 'English' 'Russian' 'Russian' 'English' 'Russian'\n",
    " 'Russian' 'English' 'English' 'Russian' 'Russian' 'English' 'English'\n",
    " 'English' 'English' 'English' 'English' 'Russian' 'English' 'Russian'\n",
    " 'Russian' 'Russian' 'Russian' 'English' 'English' 'English' 'English'] \n",
    " \n",
    "__jessica__: \n",
    "\n",
    "['Russian' 'English' 'English' 'Russian' 'English' 'English' 'Russian'\n",
    " 'English' 'English' 'English' 'English' 'Russian' 'English' 'English'\n",
    " 'English' 'English' 'English' 'English' 'English' 'English' 'English'\n",
    " 'English' 'Russian' 'English' 'English' 'English' 'English' 'English'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observe__: Although all names in the test data are English, it still identifies some trigrams as Russian. There are some trigams that happen more frequently in Russian than English hence the reason for some misidentification of Russian. This could be fixed by further training the model on more English data and gather more n-grams."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
