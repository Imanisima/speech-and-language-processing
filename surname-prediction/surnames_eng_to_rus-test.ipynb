{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Sequence Modeling - Russian and English names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Goal\n",
    "---\n",
    "\n",
    "Develop and classifier for Russian vs English surnames.\n",
    "\n",
    "In this iteration we are going to:\n",
    "* Compute bigram frequencies for English names.\n",
    "* Compute bigram frequencies for Russian names.\n",
    "* Develop a bag of bigrams model for distinguishing English and Russian names.\n",
    "* Implement Good Turing Discounting Model Smoothing\n",
    "* Test performance of model using English data.\n",
    "\n",
    "------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "import collections\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer # tokenize texts/build vocab\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer # tokenizes text and normalizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Let's perform some EDA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file into data frame.\n",
    "surname_csv = \"data_set/russian_and_english_dev.csv\"\n",
    "surname_df = pd.read_csv(surname_csv, index_col = None, encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename dev data columns.\n",
    "surname_df.rename(columns = {'Unnamed: 0':'surname', 'Unnamed: 1':'nationality'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "surname_df = surname_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Exploration\n",
    "\n",
    "We will focus on the English names and Russian names only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read english names\n",
    "# english_df = pd.read_csv(\"data_set/corpus/english_names.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# russian_df = pd.read_csv(\"data_set/corpus/russian_names.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# russian_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Bigrams\n",
    "Calculate n_grams and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ngrams and frequencies\n",
    "def generate_ngrams(names):\n",
    "    n_gram = collections.Counter()\n",
    "    n_gram_freq = 3\n",
    "    for c in names:\n",
    "        n_gram.update(Counter(c[idx : idx + n_gram_freq] for idx in range(len(c) - 1)))\n",
    "        \n",
    "    return n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting frequences in descending order\n",
    "def freq_sorted(n_gram):\n",
    "    [print(key, value) for (key, value) in sorted(n_gram.items(), key=lambda x: x[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = open(\"data_set/corpus/english_names.txt\", \"r\")\n",
    "english_names = [x.rstrip() for x in names.readlines()]\n",
    "english_names = [x.lower() for x in english_names]\n",
    "\n",
    "names = open(\"data_set/corpus/russian_names.txt\", \"r\")\n",
    "russian_names = [x.rstrip() for x in names.readlines()]\n",
    "russian_names = [x.lower() for x in russian_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve english and russian ngrams\n",
    "eng_gram = generate_ngrams(english_names)\n",
    "rus_gram = generate_ngrams(russian_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eng_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rus_gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good Turing Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_turing_smoothing(n_gram):\n",
    "    dict(n_gram)\n",
    "    smoothing = {}\n",
    "    \n",
    "    result = None\n",
    "    \n",
    "    \n",
    "    for k in n_gram:\n",
    "        result = (n_gram[k] + 1 / n_gram[k])\n",
    "        smoothing[k] = result\n",
    "        \n",
    "    return smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ The smoothing method we will use is the Good-Turing Discounting Formula. It is perfect for accounting for bigrams that have yet to occur.\n",
    "\n",
    "Equation: C^* = (c + 1) Nc+1/Nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english metaparameters\n",
    "eng_meta = good_turing_smoothing(eng_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# russian metaparameters\n",
    "rus_meta = good_turing_smoothing(rus_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating another column for when surname is English or not.\n",
    "surname_df['label_eng'] = [1 if x =='English' else 0 for x in surname_df['nationality']]\n",
    "label_eng = surname_df[\"label_eng\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating another column for when surname is Russian or not.\n",
    "surname_df['label_rus'] = [1 if x =='Russian' else 0 for x in surname_df['nationality']]\n",
    "label_rus = surname_df[\"label_rus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surname</th>\n",
       "      <th>nationality</th>\n",
       "      <th>label_eng</th>\n",
       "      <th>label_rus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mokrousov</td>\n",
       "      <td>Russian</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Nurov</td>\n",
       "      <td>Russian</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Judovich</td>\n",
       "      <td>Russian</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mikhailjants</td>\n",
       "      <td>Russian</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Jandarbiev</td>\n",
       "      <td>Russian</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        surname nationality  label_eng  label_rus\n",
       "0     Mokrousov     Russian          0          1\n",
       "1         Nurov     Russian          0          1\n",
       "2      Judovich     Russian          0          1\n",
       "3  Mikhailjants     Russian          0          1\n",
       "4    Jandarbiev     Russian          0          1"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surname_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bag of ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "surname_list = surname_df['surname'].apply(lambda x: re.sub('[^a-zA-Z]', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize features - unigrams, bigrams, and trigrams\n",
    "cv = CountVectorizer(lowercase=True, analyzer='char', ngram_range=(1,3), strip_accents=\"ascii\", min_df=0.09, max_df=1.0)\n",
    "X_freq = cv.fit_transform(surname_list)\n",
    "\n",
    "# tf_transformer for normalization\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_freq)\n",
    "X = tf_transformer.transform(X_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.25       0.         0.        ]\n",
      " [0.         0.         0.         ... 0.40824829 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.33333333 0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.5        ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1305, 28)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'an', 'b', 'c', 'ch', 'd', 'e', 'er', 'ev', 'g', 'h', 'i', 'in', 'k', 'ko', 'l', 'm', 'n', 'o', 'ov', 'p', 'r', 's', 't', 'u', 'v', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## Multiple Linear Regression\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train two (2) models: One for English and the other for Russian surnames!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metaparameters(X, meta):\n",
    "    for key in meta:\n",
    "        return meta[key] * X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eng = metaparameters(X, eng_meta)\n",
    "X_rus = metaparameters(X, rus_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English Surname Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to train the model\n",
    "x_train_eng, x_test_eng, y_train_eng, y_test_eng = train_test_split(X_eng, label_eng, test_size=0.20, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_model = LinearRegression()\n",
    "english_model.fit(x_train_eng, y_train_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Russian Surname Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rus, x_test_rus, y_train_rus, y_test_rus = train_test_split(X_rus, label_rus, test_size=0.20, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "russian_model = LinearRegression()\n",
    "russian_model.fit(x_train_rus, y_train_rus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data and Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishness_test = english_model.predict(x_test_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>label_eng</td>    <th>  R-squared (uncentered):</th>      <td>   0.651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   485.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 21 Sep 2020</td> <th>  Prob (F-statistic):</th>          <td>2.18e-61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:03:26</td>     <th>  Log-Likelihood:    </th>          <td> -88.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   261</td>      <th>  AIC:               </th>          <td>   178.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   260</td>      <th>  BIC:               </th>          <td>   181.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>    1.0113</td> <td>    0.046</td> <td>   22.027</td> <td> 0.000</td> <td>    0.921</td> <td>    1.102</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 9.104</td> <th>  Durbin-Watson:     </th> <td>   1.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.011</td> <th>  Jarque-Bera (JB):  </th> <td>   4.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.113</td> <th>  Prob(JB):          </th> <td>  0.0854</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.366</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:              label_eng   R-squared (uncentered):                   0.651\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.650\n",
       "Method:                 Least Squares   F-statistic:                              485.2\n",
       "Date:                Mon, 21 Sep 2020   Prob (F-statistic):                    2.18e-61\n",
       "Time:                        23:03:26   Log-Likelihood:                         -88.056\n",
       "No. Observations:                 261   AIC:                                      178.1\n",
       "Df Residuals:                     260   BIC:                                      181.7\n",
       "Df Model:                           1                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             1.0113      0.046     22.027      0.000       0.921       1.102\n",
       "==============================================================================\n",
       "Omnibus:                        9.104   Durbin-Watson:                   1.980\n",
       "Prob(Omnibus):                  0.011   Jarque-Bera (JB):                4.920\n",
       "Skew:                           0.113   Prob(JB):                       0.0854\n",
       "Kurtosis:                       2.366   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary of results\n",
    "from statsmodels.api import OLS\n",
    "OLS(y_test_eng, englishness_test).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "russianess_test = russian_model.predict(x_test_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>label_rus</td>    <th>  R-squared (uncentered):</th>      <td>   0.829</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.828</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   1256.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 21 Sep 2020</td> <th>  Prob (F-statistic):</th>          <td>1.53e-101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:03:26</td>     <th>  Log-Likelihood:    </th>          <td> -88.075</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   261</td>      <th>  AIC:               </th>          <td>   178.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   260</td>      <th>  BIC:               </th>          <td>   181.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>    1.0044</td> <td>    0.028</td> <td>   35.442</td> <td> 0.000</td> <td>    0.949</td> <td>    1.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 9.518</td> <th>  Durbin-Watson:     </th> <td>   1.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.009</td> <th>  Jarque-Bera (JB):  </th> <td>   5.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.121</td> <th>  Prob(JB):          </th> <td>  0.0779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.359</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:              label_rus   R-squared (uncentered):                   0.829\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.828\n",
       "Method:                 Least Squares   F-statistic:                              1256.\n",
       "Date:                Mon, 21 Sep 2020   Prob (F-statistic):                   1.53e-101\n",
       "Time:                        23:03:26   Log-Likelihood:                         -88.075\n",
       "No. Observations:                 261   AIC:                                      178.1\n",
       "Df Residuals:                     260   BIC:                                      181.7\n",
       "Df Model:                           1                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             1.0044      0.028     35.442      0.000       0.949       1.060\n",
       "==============================================================================\n",
       "Omnibus:                        9.518   Durbin-Watson:                   1.982\n",
       "Prob(Omnibus):                  0.009   Jarque-Bera (JB):                5.106\n",
       "Skew:                          -0.121   Prob(JB):                       0.0779\n",
       "Kurtosis:                       2.359   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary of results\n",
    "OLS(y_test_rus, russianess_test).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Observations\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Checking if the following names are Russian or English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Model Results: \n",
      " [ 0.43234363  0.28832746  0.40257493 -0.11332377  0.12043297  0.43754444\n",
      "  0.0987624   0.03762174] \n",
      "\n",
      "Russian Model Results: \n",
      " [0.45579119 0.57100412 0.47960615 0.89232511 0.70531972 0.45163054\n",
      " 0.72265617 0.7715687 ]\n"
     ]
    }
   ],
   "source": [
    "# predicting the following names\n",
    "names = [\"Fergus\", \"Angus\", \"Boston\", \"Austin\", \"Dankworth\", \"Denkworth\", \"Birtwistle\", \"Birdwhistle\"]\n",
    "\n",
    "reshape_feature = cv.transform(names)\n",
    "english_res = english_model.predict(reshape_feature)\n",
    "russian_res = russian_model.predict(reshape_feature)\n",
    "\n",
    "print(f\"English Model Results: \\n {english_res} \\n\")\n",
    "print(f\"Russian Model Results: \\n {russian_res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The english model does not see any of the above names as being of English origin. What's interesting is that it sees most of them more as Russian names.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Predicting the most likely possible name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening list of english names pulled from the United States Navy Academy\n",
    "names = open(\"data_set/corpus/name_catalog.txt\", \"r\")\n",
    "names_df = [x.rstrip() for x in names.readlines()]\n",
    "names_df = [x.lower() for x in names_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of names to ngrams\n",
    "name_gram = generate_ngrams(names_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write list of ngrams to a file. This will be our corpus.\n",
    "path = \"data_set/corpus/name_corpus/name_gram.txt\" \n",
    "dict(name_gram)\n",
    "f = open(path, 'w') \n",
    "for n in name_gram:\n",
    "    f.write(n + \"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mic', 'ich', 'cha', 'hae', 'ael', 'el', 'chr', 'hri', ...]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read from the corpus we just created\n",
    "corpus_root = 'data_set/corpus/name_corpus/'\n",
    "names_txt = PlaintextCorpusReader(corpus_root, '.*')\n",
    "names_txt.words('name_gram.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new english model for predicting the name\n",
    "eng_name_model = defaultdict(lambda: defaultdict(lambda: 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in names_txt.sents():\n",
    "    for c1, c2 in bigrams(sentence, pad_right=True, pad_left=True):\n",
    "        eng_name_model[c1][c2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count probabilities\n",
    "for c1 in eng_name_model:\n",
    "    total_count = float(sum(eng_name_model[c1].values()))\n",
    "    for c2 in n_gram_model[c1]:\n",
    "        eng_name_model[c1][c2] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lou -> {'oui': 2}\n",
      "ber -> {'ert': 2}\n",
      "cul -> {'ull': 2}\n",
      "ede -> {'ryl': 2}\n",
      "zjo -> {}\n"
     ]
    }
   ],
   "source": [
    "test_names = [\"Lou\", \"Ber\", \"Cul\", \"Ede\", \"Zjo\"]\n",
    "\n",
    "for name in test_names:\n",
    "    name = name.lower()\n",
    "    print(f\"{name} -> {dict(eng_name_model[name])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Improvements\n",
    "\n",
    "----\n",
    "\n",
    "The model needs to be tested on more english data. It appears to be more partial to Russian names."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
