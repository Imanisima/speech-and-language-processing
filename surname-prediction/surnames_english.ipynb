{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Sequence Modeling - Russian vs English Surnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Goal\n",
    "---\n",
    "\n",
    "Develop and classifier for Russian vs English surnames.\n",
    "\n",
    "In this iteration we are going to:\n",
    "* Compute bigram frequencies for English names.\n",
    "* Compute bigram frequencies for Russian names.\n",
    "* Develop a bag of bigrams model for distinguishing English and Russian names.\n",
    "* Implement Good Turing Discounting Model Smoothing\n",
    "* Test performance of model using English data.\n",
    "\n",
    "------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# from nltk import bigrams, trigrams, word_tokenize\n",
    "import collections\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "from nltk.corpus import brown # corpus of english words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB # Multi Naive Bayes with discrete values\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer # tokenize texts/build vocab\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer # tokenizes text and normalizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Let's perform some EDA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file into data frame.\n",
    "surname_csv = \"data_set/russian_and_english_dev.csv\"\n",
    "surname_df = pd.read_csv(surname_csv, index_col = None, encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename dev data columns.\n",
    "surname_df.rename(columns = {'Unnamed: 0':'surname', 'Unnamed: 1':'nationality'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing non-alphabetic characters \n",
    "surname_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "surname_df = surname_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1305, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surname_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "surname_df.to_csv(\"data_set/corpus/surnames_names.txt\", sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>Fairhurst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>941</td>\n",
       "      <td>Wateridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>942</td>\n",
       "      <td>Nemeth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>943</td>\n",
       "      <td>Moroney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>944</td>\n",
       "      <td>Goodall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       surname\n",
       "940  Fairhurst\n",
       "941  Wateridge\n",
       "942     Nemeth\n",
       "943    Moroney\n",
       "944    Goodall"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve English names only\n",
    "english_df = surname_df.loc[surname_df[\"nationality\"] == \"English\"]\n",
    "english_df = english_df[[\"surname\"]]\n",
    "english_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all english names in txt file\n",
    "english_df.to_csv(\"data_set/corpus/english_names.txt\", sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mokrousov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Nurov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Judovich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mikhailjants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Jandarbiev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        surname\n",
       "0     Mokrousov\n",
       "1         Nurov\n",
       "2      Judovich\n",
       "3  Mikhailjants\n",
       "4    Jandarbiev"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Russian names only\n",
    "russian_df = surname_df.loc[surname_df[\"nationality\"] == \"Russian\"]\n",
    "russian_df = russian_df[[\"surname\"]]\n",
    "russian_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_df.to_csv(\"data_set/corpus/russian_names.txt\", sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create New Corpus\n",
    "\n",
    "---\n",
    "Create a new corpus of English and Russian names to be used for the n_gram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English\n",
    "names = open(\"data_set/corpus/english_names.txt\", \"r\")\n",
    "english_names = [x.rstrip() for x in names.readlines()]\n",
    "english_names = [x.lower() for x in english_names]\n",
    "# english_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Russian\n",
    "names = open(\"data_set/corpus/russian_names.txt\", \"r\")\n",
    "russian_names = [x.rstrip() for x in names.readlines()]\n",
    "russian_names = [x.lower() for x in russian_names]\n",
    "# russian_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Calculate Frequencies and Probabilities\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate bigrams and frequencies\n",
    "def generate_bigrams(names):\n",
    "    n_gram = collections.Counter()\n",
    "    n_gram_freq = 2\n",
    "    for c in names:\n",
    "        n_gram.update(Counter(c[idx : idx + n_gram_freq] for idx in range(len(c) - 1)))\n",
    "        \n",
    "    return n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting frequences in descending order\n",
    "def freq_sorted(n_gram):\n",
    "    [print(key, value) for (key, value) in sorted(n_gram.items(), key=lambda x: x[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve english bigrams\n",
    "eng_gram = generate_bigrams(english_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "er 49\n",
      "on 47\n",
      "ar 40\n",
      "in 37\n",
      "le 37\n",
      "an 36\n",
      "ey 33\n",
      "ll 33\n",
      "ne 28\n",
      "en 26\n",
      "el 25\n",
      "ra 25\n",
      "th 23\n",
      "or 23\n",
      "re 23\n",
      "to 23\n",
      "ck 21\n",
      "ma 20\n",
      "st 19\n",
      "ri 19\n",
      "de 19\n",
      "ur 18\n",
      "es 18\n",
      "ha 17\n",
      "so 17\n",
      "la 17\n",
      "rt 16\n",
      "ke 16\n",
      "ro 15\n",
      "ho 15\n",
      "ou 15\n",
      "is 15\n",
      "al 14\n",
      "am 14\n",
      "ng 14\n",
      "ns 14\n",
      "pe 14\n",
      "nd 14\n",
      "se 14\n",
      "od 13\n",
      "ld 13\n",
      "il 13\n",
      "nn 13\n",
      "ol 13\n",
      "mo 12\n",
      "as 12\n",
      "sh 12\n",
      "tt 12\n",
      "ic 12\n",
      "wa 11\n",
      "te 11\n",
      "be 11\n",
      "rd 11\n",
      "co 11\n",
      "rs 10\n",
      "at 10\n",
      "ge 10\n",
      "ga 10\n",
      "he 10\n",
      "do 10\n",
      "ea 10\n",
      "hi 10\n",
      "rr 10\n",
      "lo 10\n",
      "oo 9\n",
      "wo 9\n",
      "ul 9\n",
      "li 9\n",
      "ki 9\n",
      "ow 9\n",
      "ir 8\n",
      "et 8\n",
      "rn 8\n",
      "gh 8\n",
      "pa 8\n",
      "ve 8\n",
      "wi 8\n",
      "we 8\n",
      "no 7\n",
      "ak 7\n",
      "tr 7\n",
      "ed 7\n",
      "rl 7\n",
      "dd 7\n",
      "vi 7\n",
      "ch 7\n",
      "oc 7\n",
      "un 7\n",
      "ei 7\n",
      "ss 7\n",
      "ad 7\n",
      "di 7\n",
      "ie 7\n",
      "hu 6\n",
      "em 6\n",
      "da 6\n",
      "ag 6\n",
      "na 6\n",
      "ut 6\n",
      "gr 6\n",
      "ee 6\n",
      "dr 6\n",
      "bi 6\n",
      "ta 6\n",
      "nt 6\n",
      "ds 6\n",
      "fo 6\n",
      "um 6\n",
      "fi 6\n",
      "ug 5\n",
      "gg 5\n",
      "it 5\n",
      "ks 5\n",
      "ay 5\n",
      "au 5\n",
      "bb 5\n",
      "ru 5\n",
      "ni 5\n",
      "ig 5\n",
      "aw 5\n",
      "dl 5\n",
      "ja 5\n",
      "ac 5\n",
      "op 5\n",
      "ls 5\n",
      "ti 5\n",
      "ry 5\n",
      "ai 4\n",
      "rh 4\n",
      "id 4\n",
      "dg 4\n",
      "me 4\n",
      "go 4\n",
      "du 4\n",
      "ot 4\n",
      "ka 4\n",
      "lm 4\n",
      "va 4\n",
      "kn 4\n",
      "gi 4\n",
      "gu 4\n",
      "tu 4\n",
      "av 4\n",
      "sm 4\n",
      "br 4\n",
      "bu 4\n",
      "us 4\n",
      "om 4\n",
      "lk 4\n",
      "cu 4\n",
      "cr 4\n",
      "pl 4\n",
      "wn 4\n",
      "ms 4\n",
      "fa 3\n",
      "rb 3\n",
      "mc 3\n",
      "ty 3\n",
      "mi 3\n",
      "gt 3\n",
      "ud 3\n",
      "oa 3\n",
      "kl 3\n",
      "ox 3\n",
      "tl 3\n",
      "ib 3\n",
      "wh 3\n",
      "ff 3\n",
      "pp 3\n",
      "rg 3\n",
      "wr 3\n",
      "fr 3\n",
      "nc 3\n",
      "sa 3\n",
      "sw 3\n",
      "po 3\n",
      "ob 3\n",
      "oy 3\n",
      "yl 3\n",
      "dm 3\n",
      "ya 3\n",
      "mp 3\n",
      "ye 3\n",
      "mm 3\n",
      "bo 3\n",
      "os 3\n",
      "si 3\n",
      "dw 3\n",
      "ys 3\n",
      "im 3\n",
      "nw 2\n",
      "ju 2\n",
      "hn 2\n",
      "rp 2\n",
      "uf 2\n",
      "ew 2\n",
      "ue 2\n",
      "gs 2\n",
      "ub 2\n",
      "su 2\n",
      "of 2\n",
      "ft 2\n",
      "pr 2\n",
      "yn 2\n",
      "sc 2\n",
      "oh 2\n",
      "dy 2\n",
      "yd 2\n",
      "lf 2\n",
      "fe 2\n",
      "nu 2\n",
      "mb 2\n",
      "nl 2\n",
      "rw 2\n",
      "nr 2\n",
      "ko 2\n",
      "tw 2\n",
      "hl 2\n",
      "nm 2\n",
      "rm 2\n",
      "lu 2\n",
      "lc 2\n",
      "yo 2\n",
      "bl 2\n",
      "rk 2\n",
      "og 2\n",
      "fl 2\n",
      "ip 2\n",
      "gl 2\n",
      "ev 2\n",
      "ba 2\n",
      "wl 2\n",
      "ui 2\n",
      "cl 2\n",
      "sp 2\n",
      "lt 2\n",
      "eb 2\n",
      "ht 2\n",
      "ah 2\n",
      "ca 1\n",
      "ia 1\n",
      "hw 1\n",
      "eh 1\n",
      "rv 1\n",
      "ct 1\n",
      "ep 1\n",
      "mu 1\n",
      "gd 1\n",
      "ci 1\n",
      "sy 1\n",
      "yk 1\n",
      "eg 1\n",
      "nf 1\n",
      "jo 1\n",
      "cc 1\n",
      "pk 1\n",
      "kr 1\n",
      "ez 1\n",
      "wt 1\n",
      "af 1\n",
      "py 1\n",
      "mn 1\n",
      "ix 1\n",
      "xo 1\n",
      "ap 1\n",
      "sf 1\n",
      "lr 1\n",
      "tc 1\n",
      "ok 1\n",
      "mk 1\n",
      "sn 1\n",
      "ov 1\n",
      "km 1\n",
      "tz 1\n",
      "zp 1\n",
      "tm 1\n",
      "ky 1\n",
      "ab 1\n",
      "ef 1\n",
      "vo 1\n",
      "by 1\n",
      "rc 1\n",
      "ce 1\n",
      "pu 1\n",
      "xv 1\n",
      "yr 1\n",
      "uv 1\n",
      "ws 1\n",
      "my 1\n",
      "yt 1\n",
      "ph 1\n",
      "ps 1\n",
      "za 1\n",
      "ao 1\n",
      "if 1\n",
      "rf 1\n",
      "eo 1\n",
      "uh 1\n",
      "fu 1\n",
      "sd 1\n",
      "xa 1\n",
      "ts 1\n"
     ]
    }
   ],
   "source": [
    "# sort freqencies\n",
    "# freq_sorted(eng_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_gram = generate_bigrams(russian_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = generate_bigrams(surname_df['surname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_sorted(rus_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__: What bigram is most informative for distinguishing between English and Russian names?\n",
    "\n",
    "__Obervation__: English top 5 bigrams:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "er: 49\n",
    "\n",
    "on: 47\n",
    "\n",
    "ar: 40\n",
    "\n",
    "in: 37\n",
    "\n",
    "le: 37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__: Russian top 5 bigrams:\n",
    "\n",
    "ov : 342\n",
    "\n",
    "in : 198\n",
    "\n",
    "ko : 159\n",
    "\n",
    "ev : 133\n",
    "\n",
    "ch : 117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = surname_df['surname'].apply(lambda x: re.sub('[^a-zA-Z]', '', x)) # features (x) needed to predict nationatlity\n",
    "target = surname_df['nationality'] # what we are predicting (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## Naiive Bayes\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English Surnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__: There are significantly more russian names in the dataset than english. The data is not quite balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(lowercase=True, analyzer='char', ngram_range=(1,4), strip_accents=\"ascii\", min_df=0.09, max_df=1.0)\n",
    "X = cv.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1305,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1305, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Data\n",
    "\n",
    "To make the data a little more accurate in it's predictions, we are going to split the surnames into train (65%) and test (35%) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to train the model\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, target, test_size=0.35, random_state = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "surname_model = GaussianNB()\n",
    "surname_model.fit(x_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surname_model.predict(x_test.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     English       0.58      0.98      0.73       135\n",
      "     Russian       0.99      0.70      0.82       322\n",
      "\n",
      "    accuracy                           0.78       457\n",
      "   macro avg       0.78      0.84      0.77       457\n",
      "weighted avg       0.87      0.78      0.79       457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[132   3]\n",
      " [ 96 226]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.7833698030634574 \n"
     ]
    }
   ],
   "source": [
    "print(f\"f1_score: {f1_score(y_test, y_pred, average='micro')} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_turing_smoothing(n_gram):\n",
    "    dict(n_gram)\n",
    "    smoothing = {}\n",
    "    \n",
    "    result = None\n",
    "    \n",
    "    \n",
    "    for k in n_gram:\n",
    "        result = (n_gram[k] + 1 / n_gram[k])\n",
    "        smoothing[k] = result\n",
    "        \n",
    "    return smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ The smoothing method we will use is the Good-Turing Discounting Formula. It is perfect for accounting for bigrams that have yet to occur.\n",
    "\n",
    "Equation: C^* = (c + 1) Nc+1/Nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english metaparameters\n",
    "eng_meta = good_turing_smoothing(eng_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# russian metaparameters\n",
    "rus_meta = good_turing_smoothing(rus_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
