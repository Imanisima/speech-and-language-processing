{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Sequence Modeling - Russian vs English Surnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Goal\n",
    "---\n",
    "\n",
    "Develop and classifier for Russian vs English surnames.\n",
    "\n",
    "In this iteration we are going to:\n",
    "* Compute bigram frequencies for English names.\n",
    "* Compute bigram frequencies for Russian names.\n",
    "* Develop a bag of bigrams model for distinguishing English and Russian names.\n",
    "* Implement Katz's Back-Off Model Smoothing\n",
    "* Test performance of model using English data.\n",
    "\n",
    "------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# from nltk import bigrams, trigrams, word_tokenize\n",
    "import collections\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "from nltk.corpus import brown # corpus of english words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import MultinomialNB # Multi Naive Bayes with discrete values\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer # tokenize texts/build vocab\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer # tokenizes text and normalizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Let's perform some EDA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file into data frame.\n",
    "surname_csv = \"data_set/russian_and_english_dev.csv\"\n",
    "surname_df = pd.read_csv(surname_csv, index_col = None, encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename dev data columns.\n",
    "surname_df.rename(columns = {'Unnamed: 0':'surname', 'Unnamed: 1':'nationality'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing non-alphabetic characters \n",
    "surname_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "surname_df = surname_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1305, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surname_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "surname_df.to_csv(\"data_set/corpus/surnames_names.txt\", sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>Fairhurst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>941</td>\n",
       "      <td>Wateridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>942</td>\n",
       "      <td>Nemeth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>943</td>\n",
       "      <td>Moroney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>944</td>\n",
       "      <td>Goodall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       surname\n",
       "940  Fairhurst\n",
       "941  Wateridge\n",
       "942     Nemeth\n",
       "943    Moroney\n",
       "944    Goodall"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve English names only\n",
    "english_df = surname_df.loc[surname_df[\"nationality\"] == \"English\"]\n",
    "english_df = english_df[[\"surname\"]]\n",
    "english_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all english names in txt file\n",
    "english_df.to_csv(\"data_set/corpus/english_names.txt\", sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mokrousov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Nurov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Judovich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mikhailjants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Jandarbiev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        surname\n",
       "0     Mokrousov\n",
       "1         Nurov\n",
       "2      Judovich\n",
       "3  Mikhailjants\n",
       "4    Jandarbiev"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Russian names only\n",
    "russian_df = surname_df.loc[surname_df[\"nationality\"] == \"Russian\"]\n",
    "russian_df = russian_df[[\"surname\"]]\n",
    "russian_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_df.to_csv(\"data_set/corpus/russian_names.txt\", sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Create New Corpus\n",
    "\n",
    "---\n",
    "Create a new corpus of English and Russian names to be used for the n_gram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English\n",
    "names = open(\"data_set/corpus/english_names.txt\", \"r\")\n",
    "english_names = [x.rstrip() for x in names.readlines()]\n",
    "english_names = [x.lower() for x in english_names]\n",
    "# english_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Russian\n",
    "names = open(\"data_set/corpus/russian_names.txt\", \"r\")\n",
    "russian_names = [x.rstrip() for x in names.readlines()]\n",
    "russian_names = [x.lower() for x in russian_names]\n",
    "# russian_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Calculate Frequencies and Probabilities\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate bigrams and frequencies\n",
    "def generate_bigrams(names):\n",
    "    n_gram = collections.Counter()\n",
    "    for c in names:\n",
    "        n_gram.update(Counter(c[idx : idx + 2] for idx in range(len(c) - 1)))\n",
    "        \n",
    "    return n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting frequences in descending order\n",
    "def freq_sorted(n_gram):\n",
    "    [print(key, value) for (key, value) in sorted(n_gram.items(), key=lambda x: x[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve english bigrams\n",
    "eng_gram = generate_bigrams(english_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort freqencies\n",
    "# freq_sorted(eng_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_gram = generate_bigrams(russian_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = generate_bigrams(surname_df['surname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_sorted(rus_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__: What bigram is most informative for distinguishing between English and Russian names?\n",
    "\n",
    "__Obervation__: English top 5 bigrams:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "er : 49\n",
    "\n",
    "on : 47\n",
    "\n",
    "ar : 40\n",
    "\n",
    "in : 37\n",
    "\n",
    "le : 37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__: Russian top 5 bigrams:\n",
    "\n",
    "ov : 342\n",
    "\n",
    "in : 198\n",
    "\n",
    "ko : 159\n",
    "\n",
    "ev : 133\n",
    "\n",
    "ch : 117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = surname_df['surname'].apply(lambda x: re.sub('[^a-zA-Z]', '', x)) # features (x) needed to predict nationatlity\n",
    "target = surname_df['nationality'] # what we are predicting (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## Naiive Bayes\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English Surnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation__: There are significantly more russian names in the dataset than english. The data is not quite balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize features - unigrams to trigrams\n",
    "# cv = CountVectorizer(lowercase=True, analyzer='char', ngram_range=(1,2), strip_accents=\"ascii\", min_df=0.0, max_df=1.0)\n",
    "# X_freq = cv.fit_transform(features.ravel())\n",
    "\n",
    "# # tf_transformer for normalization\n",
    "# tf_transformer = TfidfTransformer(use_idf=True).fit(X_freq)\n",
    "# X = tf_transformer.transform(X_freq)\n",
    "\n",
    "\n",
    "cv = CountVectorizer(lowercase=True, analyzer='char', ngram_range=(1,4), strip_accents=\"ascii\", min_df=0.09, max_df=1.0)\n",
    "X = cv.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1305,)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1305, 28)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Data\n",
    "\n",
    "To make the data a little more accurate in it's predictions, we are going to split the surnames into train (65%) and test (35%) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to train the model\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, target, test_size=0.35, random_state = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "surname_model = GaussianNB()\n",
    "surname_model.fit(x_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surname_model.predict(x_test.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     English       0.58      0.98      0.73       135\n",
      "     Russian       0.99      0.70      0.82       322\n",
      "\n",
      "    accuracy                           0.78       457\n",
      "   macro avg       0.78      0.84      0.77       457\n",
      "weighted avg       0.87      0.78      0.79       457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[132   3]\n",
      " [ 96 226]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.7833698030634574 \n"
     ]
    }
   ],
   "source": [
    "print(f\"f1_score: {f1_score(y_test, y_pred, average='micro')} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
