{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Modeling using Surnames Analysis - Japanese Surnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Hypothesis\n",
    "---\n",
    "\n",
    "To relate a name to nationality, check for the most common letter combinations/pronounciations within a specific language that makes it unique.\n",
    "\n",
    "In this iteration we are going to:\n",
    "* use naive bayes\n",
    "* compare accuracy, recall, and precision for classifying Japanese names.\n",
    "\n",
    "------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB # Multi Naive Bayes with discrete values\n",
    "from sklearn.feature_extraction.text import CountVectorizer # tokenize texts/build vocab\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Let's perform some EDA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file into data frame.\n",
    "surname_csv = \"data_set/surnames-dev.csv\"\n",
    "\n",
    "surname_df = pd.read_csv(surname_csv, index_col = None)\n",
    "\n",
    "surname_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check columns\n",
    "surname_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a glimpse at the data\n",
    "surname_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns\n",
    "surname_df.rename(columns = {'Unnamed: 0':'surname', 'Unnamed: 1':'nationality'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surname_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types of nationalities\n",
    "surname_df.nationality.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 18 unique nationalities in the dataset\n",
    "len(surname_df.nationality.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of names per nationality\n",
    "surname_df.groupby(\"nationality\")[\"surname\"].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = surname_df[\"surname\"] # features (x) needed to predict nationatlity\n",
    "target = surname_df[\"nationality\"] # what we are predicting (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Train/Test Data\n",
    "\n",
    "---\n",
    "To make the data a little more accurate in it's predictions, we are going to split the surnames into train (65%) and test (35%) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize features\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list names in the feature\n",
    "# cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to train the model\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, target, test_size=0.35, random_state = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Model Developement - Entire Model\n",
    "\n",
    "---\n",
    "Multinomial NB - entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "surname_model = MultinomialNB()\n",
    "surname_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = surname_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Accuracy-\n",
    "------\n",
    "Note: Accuracy will be computed using sklearn.metrics's ```f1_score``` library.\n",
    "\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy using test data\n",
    "surname_accuracy = f1_score(y_test, y_pred, average='micro')\n",
    "print(f\"f1 score: {surname_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation 1__: Accuracy  is at 50%.\n",
    "Possible Reasons: The amount of data used to train the model is too low or it's because there is only a small amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which nationalities is the model more accurate with\n",
    "surname_null_accuracy = y_test.value_counts().head(5) / len(y_test)\n",
    "print(surname_null_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation 2__: This model is more accurate with Russian names. Japanese surnames accuracy is at 5% compared to Russia's 48%. This could be due to Russia having the most names in this dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Precision and Recall-\n",
    "------\n",
    "Note: Precision and Recall will be computed using sklearn.metrics's ```precision_score``` and ```recall_score``` library.\n",
    "\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surname_precision = 0.0\n",
    "surname_recall = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surname_precision = precision_score(y_test, y_pred, average=\"micro\")\n",
    "surname_recall = recall_score(y_test, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"Overall\")\n",
    "print(f\"Precision: {surname_precision}\")\n",
    "print(f\"Recall: {surname_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Predictions-\n",
    "Now we will run some test predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try predicting a Japanese name\n",
    "pred_name1 = [\"Showa\"]\n",
    "reshape_feature = cv.transform(pred_name1)\n",
    "surname_model.predict(reshape_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arabic surname name\n",
    "pred_name2 = [\"Bata\"]\n",
    "reshape_feature = cv.transform(pred_name2)\n",
    "surname_model.predict(reshape_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Russian surname name\n",
    "pred_name3 = [\"Jugai\"]\n",
    "reshape_feature = cv.transform(pred_name3)\n",
    "surname_model.predict(reshape_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple names (German, English, Japanese, Arabic)\n",
    "pred_names = [\"Samuel\", \"Drew\", \"Shunji\", \"Mustafa\"]\n",
    "reshape_feature = cv.transform(pred_names)\n",
    "surname_model.predict(reshape_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation 3__: It thinks every name is Russian. This makes sense given Russian surname accuracy is almost 50% while the odds of predicting other nationalities are less than 16%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Model Developement - Japanese Surnames Only\n",
    "\n",
    "What if we train the model on only Japanese surnames?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Features Exploration-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get japanese names\n",
    "japanese_surnames = surname_df.loc[surname_df[\"nationality\"] == \"Japanese\"]\n",
    "japanese_surnames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = japanese_surnames[\"surname\"] # features (x) needed to predict nationatlity\n",
    "target = japanese_surnames[\"nationality\"] # what we are predicting (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Train/Test Data\n",
    "\n",
    "---\n",
    "To make the data a little more accurate in it's predictions, we are going to split the surnames into train (80%) and test (20%) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize features\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature names\n",
    "# cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to train the model\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, target, test_size=0.35, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "jap_surname_model = MultinomialNB()\n",
    "jap_surname_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = jap_surname_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Accuracy-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy using test data\n",
    "jap_accuracy = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"f1 score: {jap_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation 1__: Woah. That accuracy. This is solely because I only tested the model using Japanese names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Japanese names in test data\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of Japanese names in training data\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which nationalities is the model more accurate with\n",
    "null_accuracy = y_test.value_counts().head(5) / len(y_test)\n",
    "print(null_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jap_precision = 0.0\n",
    "jap_recall = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jap_precision = precision_score(y_test, y_pred, average=\"micro\")\n",
    "jap_recall = recall_score(y_test, y_pred, average=\"micro\")\n",
    "\n",
    "print(\"Japanese Surnames \")\n",
    "print(f\"Precision: {jap_precision}\")\n",
    "print(f\"Recall: {jap_recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Predictions-\n",
    "Now we will run some test predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try predicting a Japanese name\n",
    "pred_name1 = [\"Showa\"]\n",
    "reshape_feature = cv.transform(pred_name1)\n",
    "jap_surname_model.predict(reshape_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arabic surname name\n",
    "pred_name2 = [\"Bata\"]\n",
    "reshape_feature = cv.transform(pred_name2)\n",
    "jap_surname_model.predict(reshape_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Russian surname name\n",
    "pred_name3 = [\"Jugai\"]\n",
    "reshape_feature = cv.transform(pred_name3)\n",
    "jap_surname_model.predict(reshape_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple names (German, English, Japanese, Arabic)\n",
    "pred_names = [\"Samuel\", \"Drew\", \"Shunji\", \"Mustafa\"]\n",
    "reshape_feature = cv.transform(pred_names)\n",
    "jap_surname_model.predict(reshape_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation 2__: The model assumes that all names are Japanese. This is because it has been trained on no other type of name. It is all it knows. This model is biased too biased and has been overfitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### -Conclusion-\n",
    "\n",
    "Although the second model has the best accuracy, precision, and recall it is not practical. By training the dataset only on one value, it now assumes that all names are Japanese. While the test data is indeed all Japanese surnames, the model has been overfitted and so there are lots of false positives for names that have not been classified as Japanese. \n",
    "\n",
    "We will go with the first model because it is more realistic and practical.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {surname_accuracy}\")\n",
    "print(f\"Precision: {surname_precision}\")\n",
    "print(f\"Recall: {surname_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Nationality Accuracy: \\n {surname_null_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
